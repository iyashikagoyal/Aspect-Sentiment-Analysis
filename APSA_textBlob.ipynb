{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/yashikagoyal/anaconda3/lib/python3.6/site-packages/sklearn/cross_validation.py:41: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n",
      "/Users/yashikagoyal/anaconda3/lib/python3.6/site-packages/sklearn/grid_search.py:42: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. This module will be removed in 0.20.\n",
      "  DeprecationWarning)\n",
      "/Users/yashikagoyal/anaconda3/lib/python3.6/site-packages/sklearn/learning_curve.py:22: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the functions are moved. This module will be removed in 0.20\n",
      "  DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from textblob import TextBlob\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import metrics, svm, tree, ensemble, linear_model, naive_bayes\n",
    "from textblob.classifiers import NaiveBayesClassifier\n",
    "\n",
    "import pandas as pd\n",
    "import re\n",
    "import nltk\n",
    "from sklearn.feature_extraction.text import CountVectorizer        \n",
    "from nltk.stem.porter import PorterStemmer\n",
    "from sklearn import *\n",
    "import spacy\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import KFold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataTrain = pd.read_csv('data-2_train.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>example_id</th>\n",
       "      <th>text</th>\n",
       "      <th>aspect_term</th>\n",
       "      <th>term_location</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3121_0</td>\n",
       "      <td>But the staff was so horrible to us.</td>\n",
       "      <td>staff</td>\n",
       "      <td>8--13</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2777_0</td>\n",
       "      <td>To be completely fair[comma] the only redeemin...</td>\n",
       "      <td>food</td>\n",
       "      <td>57--61</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1634_0</td>\n",
       "      <td>The food is uniformly exceptional[comma] with ...</td>\n",
       "      <td>food</td>\n",
       "      <td>4--8</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1634_1</td>\n",
       "      <td>The food is uniformly exceptional[comma] with ...</td>\n",
       "      <td>kitchen</td>\n",
       "      <td>55--62</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1634_2</td>\n",
       "      <td>The food is uniformly exceptional[comma] with ...</td>\n",
       "      <td>menu</td>\n",
       "      <td>141--145</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  example_id                                               text  aspect_term  \\\n",
       "0     3121_0               But the staff was so horrible to us.        staff   \n",
       "1     2777_0  To be completely fair[comma] the only redeemin...         food   \n",
       "2     1634_0  The food is uniformly exceptional[comma] with ...         food   \n",
       "3     1634_1  The food is uniformly exceptional[comma] with ...      kitchen   \n",
       "4     1634_2  The food is uniformly exceptional[comma] with ...         menu   \n",
       "\n",
       "   term_location   class  \n",
       "0          8--13      -1  \n",
       "1         57--61       1  \n",
       "2           4--8       1  \n",
       "3         55--62       1  \n",
       "4       141--145       0  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataTrain.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataTrain.columns = ['example_id','text','aspect_term','term_location', 'class']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = dataTrain['text']\n",
    "rClass = dataTrain['class']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# testimonial = TextBlob(dataTrain['text'][0])\n",
    "# testimonial.sentiment\n",
    "# testimonial.sentiment.polarity\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X_train, X_test, y_train, y_test = train_test_split(text, rClass, test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def splitSentences(text, aspect):\n",
    "    conjuctionWords = {'any', 'also', 'but', 'that' , 'hence', 'therefore', 'if', 'only', 'so'}\n",
    "    pos = 0\n",
    "    a_pos = 0\n",
    "    array = []\n",
    "    text = text.split()\n",
    "#     print(aspect)\n",
    "    for index,t in enumerate(text):\n",
    "        \n",
    "        if t in conjuctionWords:\n",
    "#             print(t)\n",
    "            pos = index\n",
    "        if t == aspect:\n",
    "#             print(t)\n",
    "            a_pos = index\n",
    "   \n",
    "    if pos < a_pos:\n",
    "        text = text[pos+1:a_pos+len(aspect)+1]\n",
    "    else:\n",
    "        text = text[:a_pos + len(aspect) + 1]\n",
    "        \n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/yashikagoyal/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:8: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "text = dataTrain['text']\n",
    "# text = posTag(text)\n",
    "rClass = dataTrain['class']\n",
    "aspect = dataTrain['aspect_term']\n",
    "# print(text[1])\n",
    "for i in range(len(text)):\n",
    "    temp= splitSentences(text[i], aspect[i])\n",
    "    text[i] = ' '.join(temp)\n",
    "#     print(type(text[i]))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For pos Tagging\n",
    "def posTag(text1):\n",
    "    text = list()\n",
    "    for item in text1:\n",
    "        item = re.findall(r'\\w+', item)\n",
    "        item = nltk.pos_tag(item)\n",
    "        item1 = list()\n",
    "\n",
    "        lemmatizer = WordNetLemmatizer()\n",
    "        for index, g in enumerate(item):\n",
    "            if g[1] == 'NN' or g[1] == 'NNS' or g[1] == 'NNP' or g[1] == 'NNPS' or g[1] == 'JJ' or g[1] == 'JJR' or g[1] == 'JJS' or g[1] == 'IN':\n",
    "                item2 = lemmatizer.lemmatize(g[0])\n",
    "                item1.append(item2)\n",
    "\n",
    "        text.append(\" \".join(item1))\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'list' object has no attribute 'replace'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-19-7861b632a045>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtext\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreplace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"comma\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\"\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mregex\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mtext\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreplace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"\\[]\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\"\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mregex\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mtext\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlower\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mt\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtext\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mtext\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mposTag\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'list' object has no attribute 'replace'"
     ]
    }
   ],
   "source": [
    "# text=text.replace(\"comma\",\"\",regex=True)\n",
    "# text=text.replace(\"\\[]\",\"\",regex=True)\n",
    "# text = [t.lower() for t in text]\n",
    "text = posTag(text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentiment = []\n",
    "for review in text:\n",
    "    testimonial = TextBlob(review)\n",
    "    p = testimonial.sentiment.polarity\n",
    "    \n",
    "    if p >= 0.225:\n",
    "        sentiment.append(1)\n",
    "    elif p <= -0.225:\n",
    "        sentiment.append(-1)\n",
    "    else:\n",
    "        sentiment.append(0)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.5124930594114381 \n",
      "\n",
      "F1-Score of 1 class: 0.674238\n",
      "Recall of 1 class: 0.562384\n",
      "Precision of 1 class: 0.841632\n",
      "\n",
      "F1-Score of 0 class: 0.368794\n",
      "Recall of 0 class: 0.739336\n",
      "Precision of 0 class: 0.245669\n",
      "\n",
      "F1-Score of -1 class: 0.304924\n",
      "Recall of -1 class: 0.200000\n",
      "Precision of -1 class: 0.641434\n",
      "\n",
      "F1-Score of class: 0.449319\n",
      "Recall of class: 0.500574\n",
      "Precision of class: 0.576245\n"
     ]
    }
   ],
   "source": [
    "accScore = metrics.accuracy_score(rClass,sentiment)\n",
    "print('Accuracy: ', accScore,'\\n')\n",
    "lbl = [1,0,-1]\n",
    "f1Score = metrics.f1_score(rClass,sentiment,average=None,labels=lbl)\n",
    "precision = metrics.precision_score(rClass,sentiment,average=None,labels=lbl)\n",
    "recall = metrics.recall_score(rClass,sentiment,average=None,labels=lbl)\n",
    "f1=0\n",
    "p = 0;\n",
    "r=0;\n",
    "for i in range(len(lbl)):\n",
    "    print(\"F1-Score of %s class: %f\" %(lbl[i],f1Score[i]))\n",
    "    print(\"Recall of %s class: %f\" %(lbl[i],recall[i]))\n",
    "    print(\"Precision of %s class: %f\" %(lbl[i],precision[i]))\n",
    "    print()\n",
    "    f1 = f1 + f1Score[i]\n",
    "    p = p + precision[i]\n",
    "    r = r + recall[i]\n",
    "print(\"F1-Score of class: %f\" %(f1/3))\n",
    "print(\"Recall of class: %f\" %(r/3))\n",
    "print(\"Precision of class: %f\" %(p/3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
